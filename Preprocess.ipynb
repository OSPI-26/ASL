{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":46105,"databundleVersionId":5087314,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom joblib import Parallel, delayed\nfrom scipy.interpolate import interp1d\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n\nfrom sklearn.metrics import accuracy_score, f1_score\nimport matplotlib.pyplot as plt\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nBASE_PATH = \"/kaggle/input/asl-signs\"\nPREPROCESSED_PATH = \"./preprocessed_data\"\n\n# Load metadata\ntrain_csv = pd.read_csv(f\"{BASE_PATH}/train.csv\")\nwith open(f\"{BASE_PATH}/sign_to_prediction_index_map.json\", \"r\") as f:\n    label_map = json.load(f)\n\nNUM_CLASSES = len(label_map)\nprint(f\"Classes: {NUM_CLASSES}\")\n\nN_JOBS = 4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T02:02:06.732369Z","iopub.execute_input":"2026-01-21T02:02:06.732662Z","iopub.status.idle":"2026-01-21T02:02:16.162676Z","shell.execute_reply.started":"2026-01-21T02:02:06.732630Z","shell.execute_reply":"2026-01-21T02:02:16.162045Z"}},"outputs":[{"name":"stdout","text":"Classes: 250\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\ndef has_valid_hands_fast(sample_path, min_frames=5):\n    \"\"\"Filter samples with insufficient hand data\"\"\"\n    full_path = os.path.join(BASE_PATH, sample_path)\n    df = pd.read_parquet(full_path, columns=[\"frame\", \"type\"], engine=\"pyarrow\")\n    \n    hand_df = df[df[\"type\"].isin([\"left_hand\", \"right_hand\"])]\n    if hand_df.empty or hand_df[\"frame\"].nunique() < min_frames:\n        return False\n    return True\n\ndef check_index(i):\n    return i if has_valid_hands_fast(train_csv.iloc[i][\"path\"]) else None\n\n# Try loading pre-computed indices, otherwise compute\ntry:\n    valid_indices = np.load(\"/kaggle/input/valid-indices-npy/valid_indices.npy\").tolist()\n    print(f\"Loaded {len(valid_indices)} valid indices from cache\")\nexcept:\n    print(\"Computing valid indices (this may take a while)...\")\n    results = Parallel(n_jobs=N_JOBS, prefer=\"threads\")(\n        delayed(check_index)(i) for i in tqdm(range(len(train_csv)))\n    )\n    valid_indices = [i for i in results if i is not None]\n    os.makedirs(\"/kaggle/working\", exist_ok=True)\n    np.save(\"/kaggle/working/valid_indices.npy\", np.array(valid_indices))\n    print(f\"Valid samples: {len(valid_indices)} / {len(train_csv)}\")\n\n# Filter CSV to valid samples\ntrain_csv = train_csv.iloc[valid_indices].reset_index(drop=True)\nprint(f\"Filtered train_csv length: {len(train_csv)}\")\n\n\nclass LandmarkPreprocessor:\n    @staticmethod\n    def filter_empty_frames(kp, threshold=0.5):\n        \"\"\"Remove frames with too many missing landmarks\"\"\"\n        missing_per_frame = np.sum(kp == 0, axis=(1, 2)) / (kp.shape[1] * 3)\n        valid_mask = missing_per_frame < threshold\n        if np.sum(valid_mask) == 0:\n            return kp[:1]\n        return kp[valid_mask]\n    \n    @staticmethod\n    def interpolate_missing(kp):\n        T, L, C = kp.shape\n        kp_interp = kp.copy()\n        \n        for l in range(L):\n            for c in range(C):\n                track = kp[:, l, c]\n                valid_mask = track != 0\n                n_valid = np.sum(valid_mask)\n                \n                if n_valid == 0:\n                    continue\n                elif n_valid == 1:\n                    kp_interp[:, l, c] = track[valid_mask][0]\n                else:\n                    valid_indices = np.where(valid_mask)[0]\n                    valid_values = track[valid_mask]\n                    f = interp1d(valid_indices, valid_values, kind='linear',\n                               fill_value='extrapolate', bounds_error=False)\n                    kp_interp[:, l, c] = f(np.arange(T))\n        \n        return kp_interp\n    \n    @staticmethod\n    def anchor_normalize(kp):\n        \"\"\"Normalize relative to hand centroid (FIXED for hand-only data)\"\"\"\n        T, L, C = kp.shape\n        \n        # For hand landmarks, use centroid of all valid points\n        valid_mask = kp != 0\n        \n        # Calculate centroid per frame\n        anchor_pos = np.zeros((T, C))\n        scale = np.zeros(T)\n        \n        for t in range(T):\n            valid_points = kp[t][np.any(valid_mask[t], axis=1)]\n            if len(valid_points) > 0:\n                anchor_pos[t] = valid_points.mean(axis=0)\n                # Scale based on spread of points\n                distances = np.linalg.norm(valid_points - anchor_pos[t], axis=1)\n                scale[t] = distances.mean() if len(distances) > 0 else 1.0\n            else:\n                anchor_pos[t] = 0\n                scale[t] = 1.0\n        \n        # Apply normalization\n        anchor_pos_expanded = anchor_pos[:, np.newaxis, :]\n        kp_relative = kp - anchor_pos_expanded\n        \n        # Use mean scale to avoid division by zero\n        mean_scale = scale[scale > 0].mean() if np.any(scale > 0) else 1.0\n        if mean_scale > 1e-6:\n            kp_normalized = kp_relative / mean_scale\n        else:\n            kp_normalized = kp_relative\n        \n        return kp_normalized, anchor_pos, mean_scale\n\nclass LandmarkAugmentor:\n    @staticmethod\n    def horizontal_flip(kp, left_hand_indices, right_hand_indices, p=0.5):\n        \"\"\"FIXED: Proper handling of hand indices\"\"\"\n        if np.random.rand() < p:\n            kp = kp.copy()\n            kp[:, :, 0] *= -1  # Flip x-coordinate\n            \n            # Swap hands if both are present\n            if len(left_hand_indices) > 0 and len(right_hand_indices) > 0:\n                left_hand = kp[:, left_hand_indices, :].copy()\n                right_hand = kp[:, right_hand_indices, :].copy()\n                kp[:, left_hand_indices, :] = right_hand\n                kp[:, right_hand_indices, :] = left_hand\n        return kp\n    \n    @staticmethod\n    def rotation_3d(kp, max_angle=60, p=0.5):\n        if np.random.rand() < p:\n            angle = np.random.uniform(-max_angle, max_angle)\n            angle_rad = np.deg2rad(angle)\n            \n            cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)\n            R = np.array([[cos_a, -sin_a, 0], [sin_a, cos_a, 0], [0, 0, 1]])\n            \n            T, L, _ = kp.shape\n            kp_flat = kp.reshape(-1, 3)\n            kp_rotated = (R @ kp_flat.T).T\n            kp = kp_rotated.reshape(T, L, 3)\n        return kp\n    \n    @staticmethod\n    def resize_3d(kp, scale_range=(0.8, 1.2), p=0.5):\n        if np.random.rand() < p:\n            scale = np.random.uniform(*scale_range)\n            kp = kp * scale\n        return kp\n    \n    @staticmethod\n    def finger_dropout(kp, hand_indices, p_per_finger=0.1, p=0.3):\n        if np.random.rand() < p:\n            for idx in hand_indices:\n                if np.random.rand() < p_per_finger:\n                    kp[:, idx, :] = 0\n        return kp\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T02:02:16.164048Z","iopub.execute_input":"2026-01-21T02:02:16.164265Z","iopub.status.idle":"2026-01-21T02:10:16.767605Z","shell.execute_reply.started":"2026-01-21T02:02:16.164246Z","shell.execute_reply":"2026-01-21T02:10:16.766837Z"}},"outputs":[{"name":"stdout","text":"Computing valid indices (this may take a while)...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 94477/94477 [08:00<00:00, 196.62it/s]","output_type":"stream"},{"name":"stdout","text":"Valid samples: 94198 / 94477\nFiltered train_csv length: 94198\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n    \n    def forward(self, logits, targets):\n        probs = F.softmax(logits, dim=1)\n        targets_one_hot = F.one_hot(targets, num_classes=logits.shape[1])\n        p_t = (probs * targets_one_hot).sum(dim=1)\n        \n        focal_weight = (1 - p_t) ** self.gamma\n        ce_loss = F.cross_entropy(logits, targets, reduction='none')\n        focal_loss = focal_weight * ce_loss\n        \n        if self.alpha is not None:\n            if self.alpha.device != logits.device:\n                self.alpha = self.alpha.to(logits.device)\n            alpha_t = self.alpha[targets]\n            focal_loss = alpha_t * focal_loss\n        \n        if self.reduction == 'mean':\n            return focal_loss.mean()\n        elif self.reduction == 'sum':\n            return focal_loss.sum()\n        return focal_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T02:10:16.768566Z","iopub.execute_input":"2026-01-21T02:10:16.768906Z","iopub.status.idle":"2026-01-21T02:10:16.775030Z","shell.execute_reply.started":"2026-01-21T02:10:16.768885Z","shell.execute_reply":"2026-01-21T02:10:16.774432Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class ASLDataset(Dataset):\n    def __init__(self, dataframe, label_map, max_frames=64, split='train',\n                 use_anchor_norm=True, use_interpolation=True, use_augmentation=True):\n        self.df = dataframe.reset_index(drop=True)\n        self.label_map = label_map\n        self.max_frames = max_frames\n        self.split = split\n        self.use_anchor_norm = use_anchor_norm\n        self.use_interpolation = use_interpolation\n        self.use_augmentation = use_augmentation and (split == 'train')\n        \n        # Initialize helpers\n        self.preprocessor = LandmarkPreprocessor()\n        self.augmentor = LandmarkAugmentor()\n        \n        # CRITICAL: Define hand indices (42 landmarks total, 21 per hand)\n        self.left_hand_indices = list(range(0, 21))\n        self.right_hand_indices = list(range(21, 42))\n        \n        # Class balancing\n        self.class_counts = self._analyze_class_distribution()\n        self.class_weights = self._compute_class_weights()\n        \n\n        print(f\"ASL Dataset - {split.upper()}\")\n        \n        print(f\"Samples: {len(self.df)}\")\n        print(f\"Classes: {len(label_map)}\")\n        print(f\"Max frames: {max_frames}\")\n        print(f\"Anchor normalization: {use_anchor_norm}\")\n        print(f\"Interpolation: {use_interpolation}\")\n        print(f\"Augmentation: {self.use_augmentation}\")\n\n    \n    def _analyze_class_distribution(self):\n        labels = [self.label_map[row['sign']] for _, row in self.df.iterrows()]\n        return Counter(labels)\n    \n    def _compute_class_weights(self):\n        num_classes = len(self.label_map)\n        weights = np.zeros(num_classes)\n        total_samples = sum(self.class_counts.values())\n        \n        for class_idx in range(num_classes):\n            count = self.class_counts.get(class_idx, 1)\n            weights[class_idx] = total_samples / (num_classes * count)\n        \n        weights = weights / weights.sum() * num_classes\n        return torch.FloatTensor(weights)\n    \n    def get_sample_weights(self):\n        \"\"\"For WeightedRandomSampler\"\"\"\n        sample_weights = []\n        for _, row in self.df.iterrows():\n            label = self.label_map[row['sign']]\n            sample_weights.append(self.class_weights[label].item())\n        return torch.FloatTensor(sample_weights)\n    \n    def load_hand_keypoints(self, sample_path):\n        \"\"\"Load hand landmarks (42 landmarks: 21 left + 21 right)\"\"\"\n        full_path = os.path.join(BASE_PATH, sample_path)\n        df = pd.read_parquet(full_path, engine=\"pyarrow\")\n        \n        hand_df = df[df[\"type\"].isin([\"left_hand\", \"right_hand\"])]\n        hand_df = hand_df.sort_values([\"frame\", \"type\", \"landmark_index\"])\n        \n        frames = hand_df[\"frame\"].nunique()\n        coords = hand_df[[\"x\", \"y\", \"z\"]].values\n        coords = coords.reshape(frames, 42, 3)\n        \n        return np.nan_to_num(coords, nan=0.0)\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        # Load keypoints\n        kp = self.load_hand_keypoints(row[\"path\"])  # (T, 42, 3)\n        original_length = kp.shape[0]\n        \n        # Preprocessing\n        kp = self.preprocessor.filter_empty_frames(kp, threshold=0.5)\n        \n        if self.use_interpolation:\n            kp = self.preprocessor.interpolate_missing(kp)\n        \n        if self.use_anchor_norm:\n            kp, _, _ = self.preprocessor.anchor_normalize(kp)\n        \n        # Temporal resampling\n        if kp.shape[0] < self.max_frames:\n            pad_len = self.max_frames - kp.shape[0]\n            kp = np.concatenate([kp, np.zeros((pad_len, 42, 3))], axis=0)\n        elif kp.shape[0] > self.max_frames:\n            indices = np.linspace(0, kp.shape[0]-1, self.max_frames).astype(int)\n            kp = kp[indices]\n        \n        kp = np.nan_to_num(kp, nan=0.0)\n        \n        # Augmentation (FIXED with correct indices)\n        if self.use_augmentation:\n            kp = self.augmentor.horizontal_flip(\n                kp, self.left_hand_indices, self.right_hand_indices, p=0.5)\n            kp = self.augmentor.rotation_3d(kp, max_angle=60, p=0.5)\n            kp = self.augmentor.resize_3d(kp, scale_range=(0.8, 1.2), p=0.5)\n            \n            all_hand_indices = self.left_hand_indices + self.right_hand_indices\n            kp = self.augmentor.finger_dropout(kp, all_hand_indices, p=0.3)\n        \n        label = self.label_map[row[\"sign\"]]\n        \n        return torch.FloatTensor(kp), label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T02:10:16.776018Z","iopub.execute_input":"2026-01-21T02:10:16.776310Z","iopub.status.idle":"2026-01-21T02:10:16.795481Z","shell.execute_reply.started":"2026-01-21T02:10:16.776291Z","shell.execute_reply":"2026-01-21T02:10:16.794821Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def create_dataloaders(train_df, val_df, label_map, batch_size=32, \n                       max_frames=64, num_workers=4):\n    \n    train_ds = ASLDataset(\n        train_df, label_map, max_frames=max_frames, split='train',\n        use_anchor_norm=True, use_interpolation=True, use_augmentation=True\n    )\n    \n    val_ds = ASLDataset(\n        val_df, label_map, max_frames=max_frames, split='val',\n        use_anchor_norm=True, use_interpolation=True, use_augmentation=False\n    )\n    \n    # Weighted sampler for balanced training\n    sample_weights = train_ds.get_sample_weights()\n    sampler = WeightedRandomSampler(\n        weights=sample_weights,\n        num_samples=len(sample_weights),\n        replacement=True\n    )\n    \n    train_loader = DataLoader(\n        train_ds, batch_size=batch_size, sampler=sampler,\n        num_workers=num_workers, pin_memory=True,\n        prefetch_factor=2, persistent_workers=True, drop_last=True\n    )\n    \n    val_loader = DataLoader(\n        val_ds, batch_size=batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=True,\n        prefetch_factor=2, persistent_workers=True\n    )\n    \n    \n    focal_loss = FocalLoss(alpha=train_ds.class_weights, gamma=2.0)\n    \n    return train_loader, val_loader, focal_loss, train_ds.class_weights\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T02:10:16.797151Z","iopub.execute_input":"2026-01-21T02:10:16.797361Z","iopub.status.idle":"2026-01-21T02:10:16.812655Z","shell.execute_reply.started":"2026-01-21T02:10:16.797343Z","shell.execute_reply":"2026-01-21T02:10:16.811937Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    set_seed(42)\n    \n    split_idx = int(len(train_csv) * 0.8)\n    train_df = train_csv[:split_idx]\n    val_df = train_csv[split_idx:]\n    \n    print(f\"Train samples: {len(train_df)}, Val samples: {len(val_df)}\")\n    \n    train_loader, val_loader, focal_loss, class_weights = create_dataloaders(\n        train_df, val_df, label_map, \n        batch_size=32, max_frames=64, num_workers=4\n    )\n    \n    for batch_idx, (data, labels) in enumerate(train_loader):\n        print(f\"Batch shape: {data.shape}\")  # Should be [32, 64, 42, 3]\n        print(f\"Labels shape: {labels.shape}\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T02:10:16.813581Z","iopub.execute_input":"2026-01-21T02:10:16.813883Z","iopub.status.idle":"2026-01-21T02:10:24.610320Z","shell.execute_reply.started":"2026-01-21T02:10:16.813854Z","shell.execute_reply":"2026-01-21T02:10:24.604965Z"}},"outputs":[{"name":"stdout","text":"Train samples: 75358, Val samples: 18840\nASL Dataset - TRAIN\nSamples: 75358\nClasses: 250\nMax frames: 64\nAnchor normalization: True\nInterpolation: True\nAugmentation: True\nASL Dataset - VAL\nSamples: 18840\nClasses: 250\nMax frames: 64\nAnchor normalization: True\nInterpolation: True\nAugmentation: False\nBatch shape: torch.Size([32, 64, 42, 3])\nLabels shape: torch.Size([32])\n","output_type":"stream"}],"execution_count":6}]}